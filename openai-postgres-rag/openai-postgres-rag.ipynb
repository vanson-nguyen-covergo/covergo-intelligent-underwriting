{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: openai in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (1.52.0)\n",
      "Requirement already satisfied: numpy in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (2.1.2)\n",
      "Requirement already satisfied: tiktoken in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (0.8.0)\n",
      "Requirement already satisfied: psycopg2-binary in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (2.9.10)\n",
      "Requirement already satisfied: pgvector in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (0.3.5)\n",
      "Requirement already satisfied: python-dotenv in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sonnguyen/Documents/covergo/covergo-intelligent-uw/.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas openai numpy tiktoken psycopg2-binary pgvector python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken\n",
    "import psycopg2\n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Load your CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('motor_insurance_hk_data_non_pii_114423oct2024.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to help us create the embeddings\n",
    "\n",
    "# Helper func: calculate number of tokens\n",
    "def num_tokens_from_string(string: str, encoding_name = \"cl100k_base\") -> int:\n",
    "    if not string:\n",
    "        return 0\n",
    "    # Returns the number of tokens in a text string\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# Helper function: calculate length of essay\n",
    "def get_essay_length(essay):\n",
    "    word_list = essay.split()\n",
    "    num_words = len(word_list)\n",
    "    return num_words\n",
    "\n",
    "# Helper function: calculate cost of embedding num_tokens\n",
    "# Assumes we're using the text-embedding-ada-002 model\n",
    "# See https://openai.com/pricing\n",
    "def get_embedding_cost(num_tokens):\n",
    "    return num_tokens/1000*0.0002\n",
    "\n",
    "# Helper function: calculate total cost of embedding all content in the dataframe\n",
    "def get_total_embeddings_cost():\n",
    "    total_tokens = 0\n",
    "    for i in range(len(df.index)):\n",
    "        text = df['content'][i]\n",
    "        token_len = num_tokens_from_string(text)\n",
    "        total_tokens = total_tokens + token_len\n",
    "    total_cost = get_embedding_cost(total_tokens)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost = get_total_embeddings_cost()\n",
    "print(\"estimated price to embed this content = $\" + str(total_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new list with small content chunks to not hit max token limits\n",
    "# Note: the maximum number of tokens for a single request is 8191\n",
    "# https://platform.openai.com/docs/guides/embeddings/embedding-models\n",
    "\n",
    "# list for chunked content and embeddings\n",
    "new_list = []\n",
    "# Split up the text into token sizes of around 512 tokens\n",
    "for i in range(len(df.index)):\n",
    "    text = df['content'][i]\n",
    "    token_len = num_tokens_from_string(text)\n",
    "    if token_len <= 512:\n",
    "        new_list.append([df['document'][i],df['driver_id'][i],df['vehicle_id'][i],df['policy_id'][i],df['underwriting_decision'][i],df['risk_class'][i], df['reason_for_decline'][i],df['content'][i], token_len])\n",
    "    else:\n",
    "        # add content to the new list in chunks\n",
    "        start = 0\n",
    "        ideal_token_size = 512\n",
    "        # 1 token ~ 3/4 of a word\n",
    "        ideal_size = int(ideal_token_size // (4/3))\n",
    "        end = ideal_size\n",
    "        #split text by spaces into words\n",
    "        words = text.split()\n",
    "\n",
    "        #remove empty spaces\n",
    "        words = [x for x in words if x != ' ']\n",
    "\n",
    "        total_words = len(words)\n",
    "        \n",
    "        #calculate iterations\n",
    "        chunks = total_words // ideal_size\n",
    "        if total_words % ideal_size != 0:\n",
    "            chunks += 1\n",
    "        \n",
    "        new_content = []\n",
    "        for j in range(chunks):\n",
    "            if end > total_words:\n",
    "                end = total_words\n",
    "            new_content = words[start:end]\n",
    "            new_content_string = ' '.join(new_content)\n",
    "            new_content_token_len = num_tokens_from_string(new_content_string)\n",
    "            if new_content_token_len > 0:\n",
    "                new_list.append([df['document'][i],df['driver_id'][i],df['vehicle_id'][i],df['policy_id'][i],df['underwriting_decision'][i],df['risk_class'][i], df['reason_for_decline'][i],new_content_string, new_content_token_len])\n",
    "            start += ideal_size\n",
    "            end += ideal_size\n",
    "            \n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = openai.OpenAI()\n",
    "\n",
    "# Helper function: get embeddings for a text\n",
    "def get_embeddings(text):\n",
    "    response = openai_client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input = text.replace(\"\\n\",\" \")\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for each piece of content\n",
    "for i in range(len(new_list)):\n",
    "   text = new_list[i][7]\n",
    "   embedding = get_embeddings(text)\n",
    "   new_list[i].append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new_list', new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe with embeddings as a CSV file\n",
    "# Create a new dataframe from the list\n",
    "df_new = pd.DataFrame(new_list, columns=['document', 'driver_id', 'vehicle_id','policy_id', 'underwriting_decision','risk_class','reason_for_decline','content', 'tokens', 'embeddings'])\n",
    "df_new.head()\n",
    "df_new.to_csv('motor_insurance_hk_data_non_pii_114423oct2024_embeddings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timescale database connection string\n",
    "# Found under \"Service URL\" of the credential cheat-sheet or \"Connection Info\" in the Timescale console\n",
    "# In terminal, run: export TIMESCALE_CONNECTION_STRING=postgres://<fill in here>\n",
    "# export TIMESCALE_CONNECTION_STRING=postgres://your_user:your_password@your_host:your_port/your_database\n",
    "\n",
    "\n",
    "connection_string  = os.environ['TIMESCALE_CONNECTION_STRING']\n",
    "print(f\"connection_string: {connection_string}\")\n",
    "\n",
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(\"postgres://axahk_undrw_ai_app:123axahkundrwAI@localhost:5432/axahk_undrw_ai\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Register the vector type with psycopg2\n",
    "register_vector(conn)\n",
    "\n",
    "# Create table to store embeddings and metadata\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE motor_embeddings (\n",
    "            id bigserial primary key, \n",
    "            document text,\n",
    "            driver_id integer,\n",
    "            vehicle_id integer,\n",
    "            policy_id integer,\n",
    "            underwriting_decision text,\n",
    "            risk_class text,\n",
    "            reason_for_decline text,\n",
    "            content text,\n",
    "            tokens integer,\n",
    "            embedding vector(1536)\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "# cur.execute(table_create_command)\n",
    "# cur.close()\n",
    "# conn.commit()\n",
    "\n",
    "#Batch insert embeddings and metadata from dataframe into PostgreSQL database\n",
    "register_vector(conn)\n",
    "cur = conn.cursor()\n",
    "# Prepare the list of tuples to insert\n",
    "data_list = [(row['document'], int(row['driver_id']), int(row['vehicle_id']), int(row['policy_id']), row['underwriting_decision'],row['risk_class'], row['reason_for_decline'], row['content'], int(row['tokens']), np.array(row['embeddings'])) for index, row in df_new.iterrows()]\n",
    "# Use execute_values to perform batch insertion\n",
    "query = \"\"\"\n",
    "    INSERT INTO motor_embeddings \n",
    "    (document, driver_id, vehicle_id, policy_id, underwriting_decision, risk_class, reason_for_decline, content, tokens, embedding) \n",
    "    VALUES %s\n",
    "\"\"\"\n",
    "execute_values(cur, query, data_list)\n",
    "# Commit after we insert all embeddings\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) as cnt FROM motor_embeddings;\")\n",
    "num_records = cur.fetchone()[0]\n",
    "print(\"Number of vector records in table: \", num_records,\"\\n\")\n",
    "# Correct output should be 129\n",
    "\n",
    "# print the first record in the table, for sanity-checking\n",
    "cur.execute(\"SELECT * FROM motor_embeddings LIMIT 1;\")\n",
    "records = cur.fetchall()\n",
    "print(\"First record in table: \", records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index on the data for faster retrieval\n",
    "conn = psycopg2.connect(\"postgres://axahk_undrw_ai_app:123axahkundrwAI@localhost:5432/axahk_undrw_ai\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('CREATE INDEX embedding_idx ON embeddings USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Driver ID: 22901272, Age: 38, Gender: Male, Driving Experience: 30 years, Occupation: Driver, Vehicle: McLaren Speedtail, Year: 2007, Value: 552799.01 HKD, Engine Size: 1000cc, Registration City: Hong Kong, Policy ID: 7415333269, Coverage: Comprehensive, Premium: 13497.97 HKD, Policy Term: 1 year(s), Excess: 1671.82 HKD, Effective Date: 2024-01-26, Expiry Date: 2025-06-12, Renewal Status: Non-renewal, Driving Record: Multiple Accidents, Claims History: 3, Traffic Violations: 2, Vehicle Usage: Private, Credit Score: 792, Underwriting Decision: Declined, Risk Class: High Risk, Reason for Decline: Poor driving record',)\n",
      "('Driver ID: 82316958, Age: 55, Gender: Male, Driving Experience: 3 years, Occupation: Teacher, Vehicle: McLaren Speedtail, Year: 2021, Value: 783437.13 HKD, Engine Size: 1000cc, Registration City: Kowloon, Policy ID: 3609809247, Coverage: Comprehensive, Premium: 6036.6 HKD, Policy Term: 1 year(s), Excess: 1258.39 HKD, Effective Date: 2024-07-01, Expiry Date: 2024-08-27, Renewal Status: Auto-renew, Driving Record: Multiple Accidents, Claims History: 0, Traffic Violations: 1, Vehicle Usage: Private, Credit Score: 551, Underwriting Decision: Approved, Risk Class: High Risk, Reason for Decline: None',)\n",
      "('Driver ID: 57535307, Age: 34, Gender: Other, Driving Experience: 11 years, Occupation: Clerical, Vehicle: McLaren Speedtail, Year: 2007, Value: 898323.66 HKD, Engine Size: 1000cc, Registration City: New Territories, Policy ID: 8288647543, Coverage: Third Party, Premium: 18206.79 HKD, Policy Term: 1 year(s), Excess: 4717.86 HKD, Effective Date: 2024-03-13, Expiry Date: 2025-09-04, Renewal Status: Non-renewal, Driving Record: Clean, Claims History: 4, Traffic Violations: 0, Vehicle Usage: Commercial, Credit Score: 385, Underwriting Decision: Pending, Risk Class: Medium Risk, Reason for Decline: None',)\n",
      "('Driver ID: 56540729, Age: 27, Gender: Other, Driving Experience: 4 years, Occupation: Driver, Vehicle: McLaren Mulliner Batur, Year: 2006, Value: 407980.25 HKD, Engine Size: 1000cc, Registration City: New Territories, Policy ID: 4152966302, Coverage: Third Party, Premium: 10018.11 HKD, Policy Term: 1 year(s), Excess: 1929.94 HKD, Effective Date: 2024-07-08, Expiry Date: 2025-09-24, Renewal Status: Auto-renew, Driving Record: 1 Accident, Claims History: 2, Traffic Violations: 3, Vehicle Usage: Private, Credit Score: 760, Underwriting Decision: Approved, Risk Class: Medium Risk, Reason for Decline: None',)\n",
      "('Driver ID: 42858315, Age: 26, Gender: Male, Driving Experience: 6 years, Occupation: Professional, Vehicle: McLaren Mulliner Batur, Year: 2017, Value: 210341.36 HKD, Engine Size: 1500cc, Registration City: Kowloon, Policy ID: 5977459000, Coverage: Third Party, Premium: 17911.27 HKD, Policy Term: 1 year(s), Excess: 3012.11 HKD, Effective Date: 2024-09-10, Expiry Date: 2025-05-05, Renewal Status: Non-renewal, Driving Record: Clean, Claims History: 2, Traffic Violations: 2, Vehicle Usage: Commercial, Credit Score: 670, Underwriting Decision: Approved, Risk Class: High Risk, Reason for Decline: None',)\n",
      "Motor insurance risk assessment for a 45-year-old male driver with 10 years of driving experience, 3 accidents, and a McLaren Speedtail. Additionally, provide a confidence score between 1 and 10 for your assessment.\n",
      "{\n",
      "  \"id\": \"chatcmpl-ALPQ6c9UwqhXg3q9UB467gxabraAu\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"1. Underwriting Decision: Declined\\n2. Risk Class: High Risk\\n3. Reason for Decline: The driver has a history of 3 accidents, which indicates a higher likelihood of future claims. Additionally, the McLaren Speedtail is a high-value, high-performance vehicle, which further increases the risk.\\n4. Vehicle Information: \\n   - Vehicle: McLaren Speedtail\\n   - Price: Approximately 2.25 million USD\\n   - Prepared Price: Varies based on customization and market conditions\\n   - Additional Costs: High maintenance costs, insurance premiums, and potential repair costs due to the vehicle's performance capabilities and parts availability.\\n\\nConfidence Score: 8/10\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1729665966,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_a20a4ee344\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 140,\n",
      "    \"prompt_tokens\": 1148,\n",
      "    \"total_tokens\": 1288,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Question about Timescale we want the model to answer\n",
    "conn = psycopg2.connect(\"postgres://axahk_undrw_ai_app:123axahkundrwAI@localhost:5432/axahk_undrw_ai\")\n",
    "\n",
    "def get_similar_docs(query_embedding, conn, top_k):\n",
    "    embedding_array = np.array(query_embedding)\n",
    "    # Register pgvector extension\n",
    "    register_vector(conn)\n",
    "    cur = conn.cursor()\n",
    "    # Get the top k most similar documents using the KNN <=> operator\n",
    "    cur.execute(\"SELECT content FROM motor_embeddings ORDER BY embedding <=> %s LIMIT %s\", (embedding_array,top_k))\n",
    "    topk_docs = cur.fetchall()\n",
    "    for doc in topk_docs:\n",
    "        print(doc)\n",
    "    conn.commit()\n",
    "    return topk_docs\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-4o\", temperature=0, max_tokens=1000):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.to_json()\n",
    "\n",
    "def generate_dynamic_assistant_content(related_docs, k):\n",
    "    content = \"Based on similar cases, here are relevant risk assessments with additional vehicle details:\\n\"\n",
    "    \n",
    "    for i in range(min(k, len(related_docs))):\n",
    "        # Since the entire content is stored as a single field in related_docs[i][0]\n",
    "        case_details = related_docs[i][0]  # Access the full concatenated content from the database\n",
    "        \n",
    "        content += (\n",
    "            f\"{i+1}. Case Details: {case_details}\\n\"\n",
    "        )\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Function to process input with retrieval of most similar documents from the database\n",
    "def process_input_with_retrieval(user_input, top_k):\n",
    "    delimiter = \"```\"\n",
    "\n",
    "    # Step 1: Get documents related to the user input from the database\n",
    "    related_docs = get_similar_docs(get_embeddings(user_input), conn, top_k)\n",
    "\n",
    "    # Step 2: Prepare a response message using GPT-4\n",
    "    # Define the system message to enforce a structured response\n",
    "    system_message = \"\"\"\n",
    "    You are an AI assistant that provides risk assessments for motor insurance. \n",
    "    Your responses should follow this structure:\n",
    "    1. Underwriting Decision: <decision>\n",
    "    2. Risk Class: <risk_class>\n",
    "    3. Reason for Decline: <reason>\n",
    "    4. Vehicle information: <vehicle_information>\n",
    "    Should include the price, prepared price, and any additional costs to maintain it\n",
    "    Ensure that the structure is consistent and responses are concise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare messages with user input and assistant response\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{user_input}{delimiter}\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": generate_dynamic_assistant_content(related_docs, top_k)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Get the response from GPT-4\n",
    "    final_response = get_completion_from_messages(messages)\n",
    "    return final_response\n",
    "\n",
    "# Example input and response\n",
    "top_k=5\n",
    "input_text = \"Motor insurance risk assessment for a 45-year-old male driver with 10 years of driving experience, 3 accidents, and a McLaren Speedtail. Additionally, provide a confidence score between 1 and 10 for your assessment.\"\n",
    "\n",
    "response = process_input_with_retrieval(input_text, top_k)\n",
    "\n",
    "print(input_text)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
